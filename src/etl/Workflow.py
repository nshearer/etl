'''
Created on Dec 27, 2012

@author: nshearer
'''
import os

from EtlRecordSet import EtlRecordSet

class WorkflowDataPath(object):
    
    def __init__(self):
        self.src_prc_name = None
        self.src_prc = None
        self.output_name = None
        self.output_schema = None
        self.dst_prc_name = None
        self.input_name = None
        self.input_schema = None
        self.dst_prc = None


class Workflow(object):
    '''Encapsulates an ETL workflow and holds the execution context
    
    This class is used to organize all of the components in the workflow.
    
    1) add_processor() - Add Processors to generate, transform, and load 
                         record sets
    2) connect_record_set() - Connect the outputs and inputs of processors
    3) exectue() - Run the workflow to generate the desired output. 
    '''
    
    def __init__(self, data_dir_path = None, tmp_dir_path = None):
        
        self.data_dir_path = data_dir_path
        if self.data_dir_path is None:
            self.data_dir_path = os.curdir
            
        self.tmp_dir_path = tmp_dir_path
        if self.tmp_dir_path is None:
            self.tmp_dir_path = os.path.join(self.data_dir_path, 'tmp')
        
        self.__processors = dict()
        self.__record_sets = dict()
        self.__connections = dict()
        
        
    # -- Public Methods -------------------------------------------------------
        
    def add_processor(self, name, prc):
        '''Add a processor to the workflow
        
        @param name: Name to identify this processor
        @param prc: EtlProcessor class
        '''
        if self.__processors.has_key(name):
            raise IndexError("Processor '%s' already exists" % (name))
        self.__processors[name] = prc
        self.__record_sets[name] = dict()
        self.__connections[name] = dict()
        
        for p_input in prc.list_inputs():
            self.__connections[name][p_input.name] = list()
        
        
    def connect(self, from_prc_name, output_name, to_prc_name, input_name=None):
        '''Connect the output from one processor to the input of another
        
        @param from_prc_name: Name of processor producing data
        @param output_name: Name identifying dataset generated by from_prc
        @param to_prc_name: Name of processor consuming data
        @param input_name: Name of input port on to_prc to provide data on
        '''
        if input_name is None:
            input_name = output_name
        
        # Sanity Checks
        if not self.__processors.has_key(from_prc_name):
            raise KeyError("Invalid processor name: %s" % (from_prc_name))
        from_prc = self.__processors[from_prc_name]

        output_info = None
        for p_output in from_prc.list_outputs():
            if p_output.name == output_name:
                output_info = p_output
                break
        if output_info is None:
            msg = "Processor '%s' does not have an output named '%s'"
            raise KeyError(msg % (from_prc_name, output_name))
        
        if not self.__processors.has_key(to_prc_name):
            raise KeyError("Invalid processor name: %s" % (to_prc_name))
        to_prc = self.__processors[to_prc_name]
        
        input_info = None
        for p_input in to_prc.list_inputs():
            if p_input.name == input_name:
                input_info = p_input
                break
        if input_info is None:
            msg = "Processor '%s' does not have an input named '%s'"
            raise KeyError(msg % (to_prc_name, input_name))
        
        # Build connection definition
        conn = WorkflowDataPath()
        conn.src_prc_name = from_prc_name
        conn.src_prc = from_prc
        conn.output_name = output_name
        conn.output_schema = output_info.schema
        conn.dst_prc_name = to_prc_name 
        conn.dst_prc = to_prc
        conn.input_name = input_name
        conn.input_schema = input_info.schema
        
        # Add connection definition
        self.__connections[to_prc_name][input_name].append(conn)
        
        
    def execute(self, prc_name):
        '''Execute the processor (and any dependency processors) and return'''
        for p_output in self.__processors[prc_name].list_outputs():
            self.get_output(prc_name, p_output.name)
    
    
    def save_records(self, prc_name, output_name, filename):
        '''Output a record set to file for user review'''
        
        path = os.path.join(self.data_dir_path, 'reports', filename) + '.xls'
        data = self.get_output(prc_name, output_name)
        
        # Inform User
        msg = "Saving '%s' output from '%s' to %s"
        print msg % (output_name, prc_name, path)
        
        # Export
        data.export_as_excel(path)
        
        data.export_as_csv(os.path.join(self.data_dir_path, 'reports', filename) + '.csv')
        
        
    def get_output(self, prc_name, output_name):
        '''Get the output of a processor (running the processor if needed)'''
        
        # Generate record set if not cached
        if not self.__record_sets[prc_name].has_key(output_name):
            
            prc = self.__processors[prc_name]
            
            # Get required inputs
            inputs = dict()
            for p_input in prc.list_inputs():
                inputs[p_input.name] = list()
                for conn in self.__connections[prc_name][p_input.name]:
                    input_records = self.get_output(conn.src_prc_name,
                                                    conn.output_name)
                    inputs[p_input.name].append(input_records)
                    
            # Init RecordSet to contain output
            output_schema = self._get_output_schema(prc_name, output_name)
            out_records = EtlRecordSet(prc_name, output_name, output_schema)
            
            # Prepare processor
            prc.data_dir_path = self.data_dir_path
            prc.tmp_dir_path = self.tmp_dir_path
            
            # Inform User
            msg = "Running processor '%s' to generate '%s'"
            print msg % (prc_name, output_name)
            
            # Generate output
            prc.gen_output(output_name, inputs, out_records)
            
            # Cache output
            self.__record_sets[prc_name][output_name] = out_records
            
        # Returned cached output
        return self.__record_sets[prc_name][output_name]
        
        
    # -- Utility Methods ------------------------------------------------------
        
    def _get_prc_output_info(self, prc_name, output_name):
        '''Get EtlProcessorDataPort object from processor for this output'''
        if not self.__processors.has_key(prc_name):
            raise KeyError("Invalid processor name: %s" % (prc_name))
        for output in self.__processors[prc_name].list_outputs():
            if output.name == output_name:
                return output
        return None
    
    
    def _get_output_schema(self, prc_name, output_name):
        '''Get schema from processor for this output'''
        info = self._get_prc_output_info(prc_name, output_name)
        return info.schema
        
        
        
    
    